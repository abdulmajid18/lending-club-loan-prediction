# -*- coding: utf-8 -*-
"""lending Club.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CNZxf5HON-GrV43O73WxmMwnZj5AlH2h
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline 
import warnings
warnings.filterwarnings('ignore')
pd.set_option('display.max_rows', None)

data = pd.read_csv('/content/drive/My Drive/Loan Defaulters/accepted_2007_to_2018Q4.csv.gz', parse_dates=['issue_d'], infer_datetime_format=True)
data = data[(data.issue_d >= '2018-01-01 00:00:00') & (data.issue_d < '2019-01-01 00:00:00')]
data = data.reset_index(drop=True)
data.head()

data.columns

data.info()

data.shape

data.dtypes

# Obtaining the columns with more nan values with 30% nul values

drop_null_col = data.isnull().sum()/len(data)*100
drop_null_col = drop_null_col[drop_null_col.values >= 30 ]
drop_null_col = drop_null_col.index.tolist()
print(drop_null_col)
len(drop_null_col)

# dropping the drop_null_col list 
print('Dropping columns with more than 30% null values')
data.drop(labels = drop_null_col,axis = 1,inplace = True)
print(f'{len(drop_null_col)} columns dropped')

unique_counts = data.nunique()
unique_counts = unique_counts[unique_counts.values == 1].index.tolist()
# Dropping the single_unique columns 
data.drop(labels = unique_counts,axis =1, inplace=True)

drop_list_1 = ['id','funded_amnt','funded_amnt_inv','sub_grade','emp_title','issue_d']
data.drop(labels = drop_list_1,axis = 1,inplace = True)

drop_list_2 = ['url','zip_code','inq_last_6mths','out_prncp','out_prncp_inv','total_rec_prncp',
               'total_rec_int','total_rec_late_fee','recoveries','collection_recovery_fee',
                'last_pymnt_d','last_pymnt_amnt','next_pymnt_d','last_credit_pull_d']

data.drop(labels = drop_list_2,axis = 1,inplace = True)

drop_list_3 = ['mo_sin_old_rev_tl_op','mo_sin_rcnt_rev_tl_op','mo_sin_rcnt_tl','mort_acc','mths_since_recent_bc',
               'mths_since_recent_inq',         
                'num_accts_ever_120_pd',             
                'num_actv_bc_tl',                    
                'num_actv_rev_tl',                   
                'num_bc_sats',                       
                'num_bc_tl',                         
                'num_il_tl',                         
                'num_op_rev_tl',                     
                'num_rev_accts',                     
                'num_rev_tl_bal_gt_0',               
                'num_sats',                          
                'num_tl_30dpd',                      
                'num_tl_90g_dpd_24m',                
                'num_tl_op_past_12m',                
                'pct_tl_nvr_dlq',                    
                'percent_bc_gt_75',
                'mo_sin_old_il_acct',
               'last_fico_range_high',
               'last_fico_range_low',
                   ]

data.drop(labels = drop_list_3,axis=1,inplace = True)

drop_list_4 = ['total_pymnt',
 'total_pymnt_inv',
 'collections_12_mths_ex_med',
     'acc_now_delinq',
 'tot_coll_amt',
 'tot_cur_bal',
 'open_acc_6m',
 'open_act_il',
 'open_il_12m',
 'open_il_24m',
 'mths_since_rcnt_il',
 'total_bal_il',
 'il_util',
 'open_rv_12m',
 'open_rv_24m',
 'max_bal_bc',
 'all_util',
 'total_rev_hi_lim',
 'inq_fi',
 'total_cu_tl',
 'inq_last_12m',
 'acc_open_past_24mths',
 'avg_cur_bal',
 'bc_open_to_buy',
 'bc_util',
 'chargeoff_within_12_mths',
 ]

data.drop(labels = drop_list_4,axis = 1,inplace =True)

drop_list_5 = ['tax_liens',
 'tot_hi_cred_lim',
 'total_bal_ex_mort',
 'total_bc_limit',
 'total_il_high_credit_limit',
 'hardship_flag',
 'disbursement_method',
 'debt_settlement_flag']

data.drop(labels = drop_list_5,axis = 1,inplace = True)

data.columns

!pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip

from pandas_profiling import ProfileReport
#profile = ProfileReport(data, title='Pandas Profiling Report', explorative=True)
#profile.to_widgets()

#profile.to_file("/content/drive/My Drive/Loan Defaulters.html")

loan = data.loc[data['loan_status'].isin(['Fully Paid','Charged Off'])]

#profile = ProfileReport(loan, title='Pandas Profiling Report 2 ', explorative=True)
#profile.to_file('/content/drive/My Drive/Loan Defaulters.html')

loan.drop(labels = 'pymnt_plan',axis = 1,inplace = True)

# Treating the fico sccores 
# Changing the values by taking an average to form an average column 
fico_col = ['fico_range_low','fico_range_high']
loan['fico_average'] = (loan['fico_range_low'] + loan['fico_range_high']) /2

loan.drop(labels = fico_col,axis = 1,inplace= True)

profile = ProfileReport(loan, title='Pandas Profiling Report  ', explorative=True)
profile.to_file('/content/drive/My Drive/Loan Defaulters.html')

loan['loan_status'].replace(to_replace=['Fully Paid','Charged Off'],value=[1,0],inplace = True )

# Tackling the loan_amnt column
def plot_var(col):
  fig,ax = plt.subplots(1,2,figsize=(12,3))
  sns.boxplot(y = col,x = 'loan_status',data = loan,ax = ax[0])
  sns.distplot(loan[col].dropna(),bins = 50,kde = False,ax = ax[1])

plot_var('loan_amnt')

loan.groupby('loan_status')['loan_amnt'].describe()

loan['term'] = loan['term'].apply(lambda s: np.int8(s.split()[0]))

loan['term'].value_counts(normalize=True)

grp_loan = loan.groupby('loan_status')

print('Those who were able to pay the loans\n',grp_loan.get_group(1)['term'].value_counts(normalize = True))
print('Those who could not pay the the loan \n',grp_loan.get_group(0)['term'].value_counts(normalize = True))

pd.crosstab(loan['term'],loan['loan_status'],normalize = 'columns',margins=True).style.background_gradient(cmap='magma')

plot_var('installment')

loan.groupby('loan_status')['installment'].describe()

# grade
pd.crosstab(loan['grade'],loan['loan_status'],normalize = 'columns',margins=True,dropna = True).style.background_gradient(cmap='magma')

sns.countplot(x = 'grade',data = loan,hue = 'loan_status')

loan['emp_length'].replace(to_replace = ['10+ years','< 1 year'],value = ['10 years','0 years'], inplace = True)

loan['emp_length'] = loan['emp_length'].astype(str)
  def convert_int(s):
    if pd.isnull(s):
      return s
    else:
      return s.split()[0]

  loan['emp_length'] = loan['emp_length'].apply(lambda s :convert_int(s) )

sns.countplot(x = 'emp_length',data = loan,hue = 'loan_status')
#plt.xticks(rotation = 45)

# emp_length
pd.crosstab(loan['emp_length'],loan['loan_status'],normalize = 'columns',margins=True,dropna = True).style.background_gradient(cmap='magma')

# home ownership
pd.crosstab(loan['home_ownership'],loan['loan_status'],normalize = 'columns',margins=True,dropna = True).style.background_gradient(cmap='magma')

sns.countplot(x = 'home_ownership',data = loan,hue = 'loan_status')
plt.xticks(rotation = 45)

#verification status 
pd.crosstab(loan['verification_status'],loan['loan_status'],normalize = 'columns',margins=True,dropna = True).style.background_gradient(cmap='magma')

sns.countplot(x = 'verification_status',data = loan,hue = 'loan_status')
plt.xticks(rotation = 45)

pd.crosstab(loan['purpose'],loan['loan_status'],normalize = 'index').style.background_gradient(cmap='magma')

loan.groupby('purpose')['loan_status'].value_counts(normalize=True).loc[:,0].sort_values()

loan['annual_inc'].describe()

loan['log_annual_inc'] = loan['annual_inc'].apply(lambda x : np.log10(x+1))

loan.drop('annual_inc',axis = 1,inplace = True)

sns.distplot(loan['log_annual_inc'],bins=50,kde=False)

plot_var('log_annual_inc')

loan['log_annual_inc'].describe()

loan.groupby('loan_status')['log_annual_inc'].describe()

# drop the title column 
loan.drop(labels = 'title',axis = 1,inplace = True)

loan.drop(labels = 'addr_state',axis = 1,inplace = True)

plot_var('dti')

loan['dti'].sample(5)

plt.figure(figsize=(8,3), dpi=90)
sns.distplot(loan.loc[loan['dti'].notnull() & (loan['dti']<60), 'dti'], kde=False)
plt.xlabel('Debt-to-income Ratio')
plt.ylabel('Count')
plt.title('Debt-to-income Ratio')

loan.groupby('loan_status')['dti'].describe()

loan['earliest_cr_line'] = loan['earliest_cr_line'].apply(lambda s: int(s[-4:]))

loan['earliest_cr_line'].sample(3)

plot_var('earliest_cr_line')

plot_var('fico_average')

loan.groupby('loan_status')['fico_average'].describe()

plot_var('open_acc')

loan.groupby('loan_status')['open_acc'].describe()

loan.groupby('loan_status')['pub_rec'].describe()

pd.crosstab(loan['pub_rec'],loan['loan_status'],normalize = 'columns').style.background_gradient(cmap='magma')

loan['revol_bal'].describe()

loan['log_revol_bal'] = loan['revol_bal'].apply(lambda x : np.log10(x+1))

plot_var('log_revol_bal')

loan.groupby('loan_status')['log_revol_bal'].describe()

plot_var('revol_util')

loan.groupby('loan_status')['revol_util'].describe()

plot_var('total_acc')

loan.groupby('loan_status')['total_acc'].describe()

pd.crosstab(loan['initial_list_status'],loan['loan_status'],normalize = 'all').style.background_gradient(cmap='magma')

pd.crosstab(loan['application_type'],loan['loan_status'],normalize = 'all').style.background_gradient(cmap='magma')

pd.crosstab(loan['pub_rec_bankruptcies'],loan['loan_status'],normalize = 'index',margins = True).style.background_gradient(cmap='magma')

drop = ['delinq_2yrs','revol_bal','delinq_amnt']
loan.drop(labels= drop,axis = 1,inplace = True)